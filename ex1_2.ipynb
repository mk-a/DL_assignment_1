{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "#### Question 2 : Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL IMPORTS\n",
    "import mlp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import sklearn.model_selection\n",
    "import time\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE DATA\n",
    "data = pd.read_csv(\"../../mnist_train.csv\")\n",
    "data2 = pd.read_csv(\"../../mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THEM INTO TRAIN VALID TEST SETS\n",
    "X = data.values[:,1:]/255\n",
    "Y = data.values[:,0]\n",
    "X_test = data2.values[:, 1:]/255\n",
    "Y_test = data2.values[:, 0]\n",
    "X_train, X_valid, Y_train, Y_valid = sklearn.model_selection.train_test_split( X, Y, test_size=0.1666666, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape  (50000, 784)\n",
      "Valid set shape  (10000, 784)\n",
      "Test  set shape  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shape \", X_train.shape)\n",
    "print(\"Valid set shape \", X_valid.shape)\n",
    "print(\"Test  set shape \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension 784\tLayer 1 dimension 784\tLayer 2 dimension 480\tOutput dimension 10\t Initilization method glorot\tActivation function identity\n",
      "Total number of parameters : 997050\n",
      "Train on 50000 samples\tEvaluate on 10000\n",
      " samples\n",
      "Epoch 1/1\t\tTotal training time 0.0s\n",
      "\tSamples 50000/50000\tEpoch time 920.65s\tAccuracy 0.913\tLoss 0.306\tValid accuracy 0.910\t Valid loss 0.309\n",
      "\n",
      "Total training time 920.65s\n",
      "One training epoch with 50000 samples using SGD takes 0d  0h 15m\n",
      "Then the whole fine tuning should take 13d 15h 20m\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = mlp.MLP_2L(784, 784, 480, 10, init=\"glorot\")\n",
    "model.fit(X_train, Y_train, 1, 1, 0.001, validation_data=(X_valid, Y_valid), epsilon=0.05)\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "\n",
    "days = int(duration/(24 * 60 * 60))\n",
    "duration = duration % (24 * 60 * 60)\n",
    "hours = int(duration/( 60 * 60))\n",
    "duration = duration % (60 * 60)\n",
    "minutes = int(duration/60)\n",
    "\n",
    "duration2 = 4 * 128 * duration\n",
    "days2 = int(duration2/(24 * 60 * 60))\n",
    "duration2 = duration2 % (24 * 60 * 60)\n",
    "hours2 = int(duration2/( 60 * 60))\n",
    "duration2 = duration2 % (60 * 60)\n",
    "minutes2 = int(duration2/60)\n",
    "print(\"One training epoch with {:d} samples using SGD takes {:d}d {:2d}h {:2d}m\".format(X_train.shape[0],days, hours, minutes ))\n",
    "print(\"Then the whole fine tuning should take {:d}d {:2d}h {:2d}m\".format(days2, hours2, minutes2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of possibilities =  128\n"
     ]
    }
   ],
   "source": [
    "train_start = time.time()\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "count = 0\n",
    "models_perf = []\n",
    "# print(\"{:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s}\".format(\"hidden 1\", \"hidden 2\", \"activation\" , \"l_rate\", \"l1\", \"l2\",  \"accuracy\"))\n",
    "for n1 in [ 500, 784]:\n",
    "    for n2 in [300, 480]:\n",
    "        n_parameter = n1 * (input_size + 1) + n2 * (n1 + 1) + output_size * (n2 + 1)\n",
    "        if n_parameter > 1e6 or n_parameter < 5e5: continue\n",
    "        for activation in [\"identity\", \"relu\", \"sigmoid\", \"tanh\"]:\n",
    "            for learning_rate in [0.0001, 0.001 ]:\n",
    "                for l1 in [0, 1e-5]:\n",
    "                    for l2 in [0, 1e-5]:\n",
    "                        count +=1\n",
    "                        \n",
    "                        print(\"Model {:d}/128\".format(count))\n",
    "                        model = mlp.MLP_2L(input_size, n1, n2, output_size, init=\"glorot\", verbose=False)\n",
    "                        \n",
    "                        model.fit(X_train, Y_train, 2, 10, learning_rate, validation_data=(X_valid, Y_valid), epsilon=0.001 )\n",
    "                        model.fit(X_train, Y_train, 3, 1, learning_rate, validation_data=(X_valid, Y_valid), epsilon=0.001 )\n",
    "                        model.save(\"models/model\"+str(count))\n",
    "                        perf = dict()\n",
    "                        perf[\"n1\"] = n1\n",
    "                        perf[\"n2\"] = n2\n",
    "                        perf[\"activation\"] = activation\n",
    "                        perf[\"learning_rate\"] = learning_rate\n",
    "                        perf[\"l1\"] = l1\n",
    "                        perf[\"l2\"] = l2\n",
    "                        perf[\"accuracy\"] = model.evaluate(X_valid, Y_valid)\n",
    "                        \n",
    "                        models_perf.append(perf)\n",
    "train_end = time.time()\n",
    "duration3 = train_end - train_start\n",
    "days3 = int(duration3/(24 * 60 * 60))\n",
    "duration3 = duration3 % (24 * 60 * 60)\n",
    "hours3 = int(duration3/( 60 * 60))\n",
    "duration3 = duration3 % (60 * 60)\n",
    "minutes3 = int(duration3/60)\n",
    "\n",
    "print(\"Then the whole fine tuning took {:d}d {:2d}h {:2d}m\".format(days3, hours3, minutes3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One training epoch with 10 samples using SGD takes 0d  6h 30m\n"
     ]
    }
   ],
   "source": [
    "print(\"{:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s}\".format(\"hidden 1\", \"hidden 2\", \"activation\" , \"l_rate\", \"l1\", \"l2\",  \"accuracy\"))\n",
    "print(\"________________________________________________________________________________________________\")\n",
    "for perf in models_perf:\n",
    "    print(\"{:^10d} | {:^10d} | {:^10s} | {:^10f} | {:^10f} | {:^10f} | {:^10f}\".format(perf[\"n1\"], perf[\"n2\"] , perf[\"activation\"], perf[\"learning_rate\"], perf[\"l1\"], perf[\"l2\"], perf[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
